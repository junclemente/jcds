{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to jcds \ud83e\uddea","text":"<p>jcds is a personal collection of reusable Python functions for data science workflows, built to save time and reduce repetition in Jupyter notebooks.</p> <p>It provides: - \ud83d\udd0e Quick EDA tools (like <code>quick_report</code> and <code>long_report</code>) - \ud83d\udcca Helpers for working with categorical and continuous variables - \ud83e\uddf9 Utilities for inspecting, cleaning, and summarizing data - \u2601\ufe0f Optional AWS integration for working with S3 - \ud83e\uddea Well-tested functions using <code>pytest</code></p>"},{"location":"#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"#1-installation","title":"1. Installation","text":"<p>Install the latest version directly from GitHub:</p> <pre><code>pip install git+https://github.com/junclemente/jcds.git\n</code></pre> <p>Or with AWS extras: </p> <pre><code>pip install git+https://github.com/junclemente/jcds.git[aws]\n</code></pre>"},{"location":"#basic-example","title":"Basic Example","text":"<pre><code>import pandas as pd\nimport jcds.eda as jeda \n\ndf = pd.read_csv(\"your_dataset.csv\")\nduplicates = jeda.show_dupes(df)\nprint(duplicates)\n\nunique_values_list = jeda.count_unique_values(df, ['col1', 'col2', 'col3'])\nprint(unique_values_list)\n\nunique_values_column = jeda.count_unique_values(df, 'col')\nprint(unique_values_column)\n\n</code></pre> <p>Check out the API Reference to explore all available functions.</p>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#eda-inspect","title":"EDA Inspect","text":""},{"location":"api/#jcds.eda.inspect.count_cols_with_all_na","title":"<code>count_cols_with_all_na(dataframe)</code>","text":"<p>Count the number of columns in the DataFrame where all values are missing (NaN).</p>"},{"location":"api/#jcds.eda.inspect.count_cols_with_all_na--parameters","title":"Parameters","text":"<p>dataframe : pd.DataFrame     The input pandas DataFrame.</p>"},{"location":"api/#jcds.eda.inspect.count_cols_with_all_na--returns","title":"Returns","text":"<p>int     The number of columns where every row is NaN.</p> <p>Docstring generated with assistance from ChatGPT.</p> Source code in <code>jcds/eda/inspect.py</code> <pre><code>def count_cols_with_all_na(dataframe):\n    \"\"\"\n    Count the number of columns in the DataFrame where all values are missing (NaN).\n\n    Parameters\n    ----------\n    dataframe : pd.DataFrame\n        The input pandas DataFrame.\n\n    Returns\n    -------\n    int\n        The number of columns where every row is NaN.\n\n    Docstring generated with assistance from ChatGPT.\n    \"\"\"\n\n    return dataframe.isna().all(axis=0).sum()\n</code></pre>"},{"location":"api/#jcds.eda.inspect.count_cols_with_any_na","title":"<code>count_cols_with_any_na(dataframe)</code>","text":"<p>Count the number of columns in the DataFrame that contain at least one missing (NaN) value.</p>"},{"location":"api/#jcds.eda.inspect.count_cols_with_any_na--parameters","title":"Parameters","text":"<p>dataframe : pd.DataFrame     The input pandas DataFrame.</p>"},{"location":"api/#jcds.eda.inspect.count_cols_with_any_na--returns","title":"Returns","text":"<p>int     The number of columns with at least one NaN value.</p> <p>Docstring generated with assistance from ChatGPT.</p> Source code in <code>jcds/eda/inspect.py</code> <pre><code>def count_cols_with_any_na(dataframe):\n    \"\"\"\n    Count the number of columns in the DataFrame that contain at least one missing (NaN) value.\n\n    Parameters\n    ----------\n    dataframe : pd.DataFrame\n        The input pandas DataFrame.\n\n    Returns\n    -------\n    int\n        The number of columns with at least one NaN value.\n\n    Docstring generated with assistance from ChatGPT.\n    \"\"\"\n\n    return dataframe.isna().any(axis=0).sum()\n</code></pre>"},{"location":"api/#jcds.eda.inspect.count_rows_with_all_na","title":"<code>count_rows_with_all_na(dataframe)</code>","text":"<p>Count the number of rows in the DataFrame where all values are missing (NaN).</p>"},{"location":"api/#jcds.eda.inspect.count_rows_with_all_na--parameters","title":"Parameters","text":"<p>dataframe : pd.DataFrame     The input pandas DataFrame.</p>"},{"location":"api/#jcds.eda.inspect.count_rows_with_all_na--returns","title":"Returns","text":"<p>int     The number of rows where every column is NaN.</p> <p>Docstring generated with assistance from ChatGPT.</p> Source code in <code>jcds/eda/inspect.py</code> <pre><code>def count_rows_with_all_na(dataframe):\n    \"\"\"\n    Count the number of rows in the DataFrame where all values are missing (NaN).\n\n    Parameters\n    ----------\n    dataframe : pd.DataFrame\n        The input pandas DataFrame.\n\n    Returns\n    -------\n    int\n        The number of rows where every column is NaN.\n\n    Docstring generated with assistance from ChatGPT.\n    \"\"\"\n\n    return dataframe.isna().all(axis=1).sum()\n</code></pre>"},{"location":"api/#jcds.eda.inspect.count_rows_with_any_na","title":"<code>count_rows_with_any_na(dataframe)</code>","text":"<p>Count the number of rows in the DataFrame that contain at least one missing (NaN) value.</p>"},{"location":"api/#jcds.eda.inspect.count_rows_with_any_na--parameters","title":"Parameters","text":"<p>dataframe : pd.DataFrame     The input pandas DataFrame.</p>"},{"location":"api/#jcds.eda.inspect.count_rows_with_any_na--returns","title":"Returns","text":"<p>int     The number of rows with at least one NaN value.</p> <p>Docstring generated with assistance from ChatGPT.</p> Source code in <code>jcds/eda/inspect.py</code> <pre><code>def count_rows_with_any_na(dataframe):\n    \"\"\"\n    Count the number of rows in the DataFrame that contain at least one missing (NaN) value.\n\n    Parameters\n    ----------\n    dataframe : pd.DataFrame\n        The input pandas DataFrame.\n\n    Returns\n    -------\n    int\n        The number of rows with at least one NaN value.\n\n    Docstring generated with assistance from ChatGPT.\n    \"\"\"\n\n    return dataframe.isna().any(axis=1).sum()\n</code></pre>"},{"location":"api/#jcds.eda.inspect.count_total_na","title":"<code>count_total_na(dataframe)</code>","text":"<p>Calculate the total number of missing (NaN) values in the entire DataFrame.</p>"},{"location":"api/#jcds.eda.inspect.count_total_na--parameters","title":"Parameters","text":"<p>dataframe : pd.DataFrame     The input pandas DataFrame.</p>"},{"location":"api/#jcds.eda.inspect.count_total_na--returns","title":"Returns","text":"<p>int     The total count of NaN values in the DataFrame.</p> <p>Docstring generated with assistance from ChatGPT.</p> Source code in <code>jcds/eda/inspect.py</code> <pre><code>def count_total_na(dataframe):\n    \"\"\"\n    Calculate the total number of missing (NaN) values in the entire DataFrame.\n\n    Parameters\n    ----------\n    dataframe : pd.DataFrame\n        The input pandas DataFrame.\n\n    Returns\n    -------\n    int\n        The total count of NaN values in the DataFrame.\n\n    Docstring generated with assistance from ChatGPT.\n    \"\"\"\n\n    return dataframe.isna().sum().sum()\n</code></pre>"},{"location":"api/#jcds.eda.inspect.count_unique_values","title":"<code>count_unique_values(dataframe, columns)</code>","text":"<p>Count the number of unique values in the specified columns of a DataFrame, including NaNs.</p>"},{"location":"api/#jcds.eda.inspect.count_unique_values--parameters","title":"Parameters","text":"<p>dataframe : pd.DataFrame     The input pandas DataFrame. columns : list of str     A list of column names for which to count unique values.</p>"},{"location":"api/#jcds.eda.inspect.count_unique_values--returns","title":"Returns","text":"<p>dict     A dictionary where each key is a column name and the value is the count of unique entries, including NaNs.</p> <p>Docstring generated with assistance from ChatGPT.</p> Source code in <code>jcds/eda/inspect.py</code> <pre><code>def count_unique_values(dataframe, columns):\n    \"\"\"\n    Count the number of unique values in the specified columns of a DataFrame, including NaNs.\n\n    Parameters\n    ----------\n    dataframe : pd.DataFrame\n        The input pandas DataFrame.\n    columns : list of str\n        A list of column names for which to count unique values.\n\n    Returns\n    -------\n    dict\n        A dictionary where each key is a column name and the value is the count of unique entries, including NaNs.\n\n    Docstring generated with assistance from ChatGPT.\n    \"\"\"\n\n    unique_counts = {}\n    for col in columns:\n        count = dataframe[col].nunique(dropna=False)\n        unique_counts[col] = count\n    return unique_counts\n</code></pre>"},{"location":"api/#jcds.eda.inspect.show_binary_list","title":"<code>show_binary_list(dataframe, dropna=True)</code>","text":"<p>Identify binary columns in a DataFrame, optionally considering missing values.</p>"},{"location":"api/#jcds.eda.inspect.show_binary_list--parameters","title":"Parameters","text":"<p>dataframe : pd.DataFrame     The input pandas DataFrame. dropna : bool, optional     If True, NaN values are excluded when determining binary columns. Default is True.</p>"},{"location":"api/#jcds.eda.inspect.show_binary_list--returns","title":"Returns","text":"<p>dict     A dictionary with two keys:         - \"binary_columns\": list of column names that contain exactly two unique non-null values.         - \"binary_with_nan\": list of column names that have two unique non-null values and also include NaNs.</p> <p>Docstring generated with assistance from ChatGPT.</p> Source code in <code>jcds/eda/inspect.py</code> <pre><code>def show_binary_list(dataframe, dropna=True):\n    \"\"\"\n    Identify binary columns in a DataFrame, optionally considering missing values.\n\n    Parameters\n    ----------\n    dataframe : pd.DataFrame\n        The input pandas DataFrame.\n    dropna : bool, optional\n        If True, NaN values are excluded when determining binary columns. Default is True.\n\n    Returns\n    -------\n    dict\n        A dictionary with two keys:\n            - \"binary_columns\": list of column names that contain exactly two unique non-null values.\n            - \"binary_with_nan\": list of column names that have two unique non-null values and also include NaNs.\n\n    Docstring generated with assistance from ChatGPT.\n    \"\"\"\n\n    binary_cols = []\n    binary_with_nan = []\n    for col in dataframe.columns:\n        unique_vals = dataframe[col].unique()\n        unique_vals_no_nan = pd.Series(unique_vals).dropna().unique()\n\n        if len(unique_vals_no_nan) == 2:\n            if pd.isna(unique_vals).any():\n                binary_with_nan.append(col)\n            else:\n                binary_cols.append(col)\n\n    return {\"binary_columns\": binary_cols, \"binary_with_nan\": binary_with_nan}\n</code></pre>"},{"location":"api/#jcds.eda.inspect.show_catvar","title":"<code>show_catvar(dataframe)</code>","text":"<p>Identify and return a list of categorical variables in the DataFrame.</p>"},{"location":"api/#jcds.eda.inspect.show_catvar--parameters","title":"Parameters","text":"<p>dataframe : pd.DataFrame     The input pandas DataFrame.</p>"},{"location":"api/#jcds.eda.inspect.show_catvar--returns","title":"Returns","text":"<p>list of str     A list of column names that have categorical or object data types.</p> <p>Docstring generated with assistance from ChatGPT.</p> Source code in <code>jcds/eda/inspect.py</code> <pre><code>def show_catvar(dataframe):\n    \"\"\"\n    Identify and return a list of categorical variables in the DataFrame.\n\n    Parameters\n    ----------\n    dataframe : pd.DataFrame\n        The input pandas DataFrame.\n\n    Returns\n    -------\n    list of str\n        A list of column names that have categorical or object data types.\n\n    Docstring generated with assistance from ChatGPT.\n    \"\"\"\n    cat_features = dataframe.select_dtypes(\n        include=[\"category\", \"object\"]\n    ).columns.tolist()\n    return cat_features\n</code></pre>"},{"location":"api/#jcds.eda.inspect.show_convar","title":"<code>show_convar(dataframe)</code>","text":"<p>Identify and return a list of continuous (non-categorical) variables in the DataFrame.</p>"},{"location":"api/#jcds.eda.inspect.show_convar--parameters","title":"Parameters","text":"<p>dataframe : pd.DataFrame     The input pandas DataFrame.</p>"},{"location":"api/#jcds.eda.inspect.show_convar--returns","title":"Returns","text":"<p>list of str     A list of column names that are not of categorical or object data types.</p> <p>Docstring generated with assistance from ChatGPT.</p> Source code in <code>jcds/eda/inspect.py</code> <pre><code>def show_convar(dataframe):\n    \"\"\"\n    Identify and return a list of continuous (non-categorical) variables in the DataFrame.\n\n    Parameters\n    ----------\n    dataframe : pd.DataFrame\n        The input pandas DataFrame.\n\n    Returns\n    -------\n    list of str\n        A list of column names that are not of categorical or object data types.\n\n    Docstring generated with assistance from ChatGPT.\n    \"\"\"\n\n    cont_features = dataframe.select_dtypes(\n        exclude=[\"category\", \"object\"]\n    ).columns.tolist()\n    return cont_features\n</code></pre>"},{"location":"api/#jcds.eda.inspect.show_dupes","title":"<code>show_dupes(dataframe)</code>","text":"<p>Return the number of duplicate rows in the given DataFrame.</p>"},{"location":"api/#jcds.eda.inspect.show_dupes--parameters","title":"Parameters","text":"<p>dataframe : pd.DataFrame     The input pandas DataFrame.</p>"},{"location":"api/#jcds.eda.inspect.show_dupes--returns","title":"Returns","text":"<p>int     The count of duplicated rows in the DataFrame.</p> <p>Docstring generated with assistance from ChatGPT.</p> Source code in <code>jcds/eda/inspect.py</code> <pre><code>def show_dupes(dataframe):\n    \"\"\"\n    Return the number of duplicate rows in the given DataFrame.\n\n    Parameters\n    ----------\n    dataframe : pd.DataFrame\n        The input pandas DataFrame.\n\n    Returns\n    -------\n    int\n        The count of duplicated rows in the DataFrame.\n\n    Docstring generated with assistance from ChatGPT.\n    \"\"\"\n    dupes = dataframe.duplicated()\n    return dupes.sum()\n</code></pre>"},{"location":"api/#jcds.eda.inspect.show_lowcardvars","title":"<code>show_lowcardvars(dataframe, max_unique=10)</code>","text":"<p>Return a list of categorical variables with unique values less than or equal to the specified threshold.</p>"},{"location":"api/#jcds.eda.inspect.show_lowcardvars--parameters","title":"Parameters","text":"<p>dataframe : pd.DataFrame     The input pandas DataFrame. max_unique : int, optional     The maximum number of unique values allowed for a variable to be considered low cardinality. Default is 10.</p>"},{"location":"api/#jcds.eda.inspect.show_lowcardvars--returns","title":"Returns","text":"<p>list of tuple     A list of tuples where each tuple contains the column name and the number of unique values.</p> <p>Docstring generated with assistance from ChatGPT.</p> Source code in <code>jcds/eda/inspect.py</code> <pre><code>def show_lowcardvars(dataframe, max_unique=10):\n    \"\"\"\n    Return a list of categorical variables with unique values less than or equal to the specified threshold.\n\n    Parameters\n    ----------\n    dataframe : pd.DataFrame\n        The input pandas DataFrame.\n    max_unique : int, optional\n        The maximum number of unique values allowed for a variable to be considered low cardinality. Default is 10.\n\n    Returns\n    -------\n    list of tuple\n        A list of tuples where each tuple contains the column name and the number of unique values.\n\n    Docstring generated with assistance from ChatGPT.\n    \"\"\"\n\n    print(f\"Showing cat var of cardinality &lt;= {max_unique}\")\n    col_list = []\n    cols = show_catvar(dataframe)\n    for col in cols:\n        count = dataframe[col].nunique()\n        if count &lt;= max_unique:\n            col_list.append((col, count))\n    return col_list\n</code></pre>"},{"location":"api/#jcds.eda.inspect.show_shape","title":"<code>show_shape(dataframe)</code>","text":"<p>Return the shape (number of rows and columns) of the given DataFrame.</p>"},{"location":"api/#jcds.eda.inspect.show_shape--parameters","title":"Parameters","text":"<p>dataframe : pd.DataFrame     The input pandas DataFrame.</p>"},{"location":"api/#jcds.eda.inspect.show_shape--returns","title":"Returns","text":"<p>tuple of int     A tuple containing the number of rows and columns in the DataFrame.</p> <p>Docstring generated with assistance from ChatGPT.</p> Source code in <code>jcds/eda/inspect.py</code> <pre><code>def show_shape(dataframe):\n    \"\"\"\n    Return the shape (number of rows and columns) of the given DataFrame.\n\n    Parameters\n    ----------\n    dataframe : pd.DataFrame\n        The input pandas DataFrame.\n\n    Returns\n    -------\n    tuple of int\n        A tuple containing the number of rows and columns in the DataFrame.\n\n    Docstring generated with assistance from ChatGPT.\n    \"\"\"\n    return dataframe.shape\n</code></pre>"},{"location":"api/#column-utilities","title":"Column Utilities","text":""},{"location":"api/#jcds.eda.lists.get_cat_list","title":"<code>get_cat_list(dataframe)</code>","text":"<p>Return a list of categorical column names or the subset of the DataFrame containing only categorical columns.</p>"},{"location":"api/#jcds.eda.lists.get_cat_list--parameters","title":"Parameters","text":"<p>dataframe : pd.DataFrame     The DataFrame to analyze. return_names : bool     If True, returns a list of column names. If False, returns a DataFrame slice.</p>"},{"location":"api/#jcds.eda.lists.get_cat_list--returns","title":"Returns","text":"<p>list of str or pd.DataFrame     Categorical column names if <code>return_names</code> is True, or a DataFrame containing only categorical columns if False.</p> <p>Docstring generated with assistance from ChatGPT.</p> Source code in <code>jcds/eda/lists.py</code> <pre><code>def get_cat_list(dataframe):\n    \"\"\"\n    Return a list of categorical column names or the subset of the DataFrame containing only categorical columns.\n\n    Parameters\n    ----------\n    dataframe : pd.DataFrame\n        The DataFrame to analyze.\n    return_names : bool\n        If True, returns a list of column names. If False, returns a DataFrame slice.\n\n    Returns\n    -------\n    list of str or pd.DataFrame\n        Categorical column names if `return_names` is True, or a DataFrame containing only categorical columns if False.\n\n    Docstring generated with assistance from ChatGPT.\n    \"\"\"\n\n    cat_list = dataframe.select_dtypes(include=[\"category\", \"object\"]).columns.tolist()\n    return cat_list\n</code></pre>"},{"location":"api/#jcds.eda.lists.get_cont_list","title":"<code>get_cont_list(dataframe)</code>","text":"<p>Return a list of continuous (non-categorical) column names or the subset of the DataFrame containing only continuous columns.</p>"},{"location":"api/#jcds.eda.lists.get_cont_list--parameters","title":"Parameters","text":"<p>dataframe : pd.DataFrame     The DataFrame to analyze. return_names : bool     If True, returns a list of column names. If False, returns a DataFrame slice.</p>"},{"location":"api/#jcds.eda.lists.get_cont_list--returns","title":"Returns","text":"<p>list of str or pd.DataFrame     Continuous column names if <code>return_names</code> is True, or a DataFrame containing only continuous columns if False.</p> <p>Docstring generated with assistance from ChatGPT.</p> Source code in <code>jcds/eda/lists.py</code> <pre><code>def get_cont_list(dataframe):\n    \"\"\"\n    Return a list of continuous (non-categorical) column names or the subset of the DataFrame containing only continuous columns.\n\n    Parameters\n    ----------\n    dataframe : pd.DataFrame\n        The DataFrame to analyze.\n    return_names : bool\n        If True, returns a list of column names. If False, returns a DataFrame slice.\n\n    Returns\n    -------\n    list of str or pd.DataFrame\n        Continuous column names if `return_names` is True, or a DataFrame containing only continuous columns if False.\n\n    Docstring generated with assistance from ChatGPT.\n    \"\"\"\n\n    cont_list = dataframe.select_dtypes(exclude=[\"category\", \"object\"]).columns.tolist()\n    return cont_list\n</code></pre>"},{"location":"api/#jcds.eda.lists.list_unique_values","title":"<code>list_unique_values(dataframe, column)</code>","text":"<p>Print the unique values in one or more specified columns of a DataFrame and display the corresponding code snippet.</p>"},{"location":"api/#jcds.eda.lists.list_unique_values--parameters","title":"Parameters","text":"<p>dataframe : pd.DataFrame     The input pandas DataFrame. column : str or list of str     The column name or list of column names to inspect for unique values.</p>"},{"location":"api/#jcds.eda.lists.list_unique_values--returns","title":"Returns","text":"<p>None     This function prints output to the console and does not return a value.</p> <p>Docstring generated with assistance from ChatGPT.</p> Source code in <code>jcds/eda/lists.py</code> <pre><code>def list_unique_values(dataframe, column):\n    \"\"\"\n    Print the unique values in one or more specified columns of a DataFrame and display the corresponding code snippet.\n\n    Parameters\n    ----------\n    dataframe : pd.DataFrame\n        The input pandas DataFrame.\n    column : str or list of str\n        The column name or list of column names to inspect for unique values.\n\n    Returns\n    -------\n    None\n        This function prints output to the console and does not return a value.\n\n    Docstring generated with assistance from ChatGPT.\n    \"\"\"\n    display_code = f'DataFrame[\"{column}\"].unique().tolist()'\n    print_code_line(display_code)\n\n    if isinstance(column, list):\n        for col in column:\n            print(f\"Unique values in '{col}':\")\n            print(dataframe[col].unique().tolist())\n            print(\"---\")\n    else:\n        print(f\"Unique values in '{column}':\")\n        print(dataframe[column].unique().tolist())\n</code></pre>"},{"location":"api/#datetime-utilities","title":"Datetime Utilities","text":""},{"location":"api/#jcds.eda.datetime.create_dt_col","title":"<code>create_dt_col(dataframe, datetime_col, col_type='month')</code>","text":"<p>Wrapper for create_dt_cols that creates a single datetime-derived column.</p>"},{"location":"api/#jcds.eda.datetime.create_dt_col--parameters","title":"Parameters","text":"<p>dataframe : DataFrame     The input DataFrame. datetime_col : str     Name of the column containing datetime values. col_type : str     A single datetime component to extract.</p>"},{"location":"api/#jcds.eda.datetime.create_dt_col--returns","title":"Returns","text":"<p>DataFrame     A copy of the DataFrame with one new datetime feature column added.</p> <p>Docstring generated with assistance from ChatGPT.</p> Source code in <code>jcds/eda/datetime.py</code> <pre><code>def create_dt_col(dataframe, datetime_col, col_type=\"month\"):\n    \"\"\"\n    Wrapper for create_dt_cols that creates a single datetime-derived column.\n\n    Parameters\n    ----------\n    dataframe : DataFrame\n        The input DataFrame.\n    datetime_col : str\n        Name of the column containing datetime values.\n    col_type : str\n        A single datetime component to extract.\n\n    Returns\n    -------\n    DataFrame\n        A copy of the DataFrame with one new datetime feature column added.\n\n    Docstring generated with assistance from ChatGPT.\n    \"\"\"\n    return create_dt_cols(dataframe, datetime_col, [col_type])\n</code></pre>"},{"location":"api/#jcds.eda.datetime.create_dt_cols","title":"<code>create_dt_cols(dataframe, datetime_col, col_types=['month'])</code>","text":"<p>Add one or more datetime-derived columns to a DataFrame from a single datetime column.</p>"},{"location":"api/#jcds.eda.datetime.create_dt_cols--parameters","title":"Parameters","text":"<p>dataframe : DataFrame     The input DataFrame. datetime_col : str     Name of the column containing datetime values. col_types : str or list of str, default [\"month\"]     One or more datetime components to extract. Supported values:     \"year\", \"month\", \"day\", \"weekday\", \"weekday_name\", \"weekofyear\",     \"quarter\", \"is_weekend\", \"dayofyear\", \"is_month_start\", \"is_month_end\".</p>"},{"location":"api/#jcds.eda.datetime.create_dt_cols--returns","title":"Returns","text":"<p>DataFrame     A copy of the DataFrame with the new datetime feature columns added.</p>"},{"location":"api/#jcds.eda.datetime.create_dt_cols--raises","title":"Raises","text":"<p>ValueError     If the datetime_col is missing or if any component in col_types is unsupported.</p> <p>Docstring generated with assistance from ChatGPT.</p> Source code in <code>jcds/eda/datetime.py</code> <pre><code>def create_dt_cols(dataframe, datetime_col, col_types=[\"month\"]):\n    \"\"\"\n    Add one or more datetime-derived columns to a DataFrame from a single datetime column.\n\n    Parameters\n    ----------\n    dataframe : DataFrame\n        The input DataFrame.\n    datetime_col : str\n        Name of the column containing datetime values.\n    col_types : str or list of str, default [\"month\"]\n        One or more datetime components to extract. Supported values:\n        \"year\", \"month\", \"day\", \"weekday\", \"weekday_name\", \"weekofyear\",\n        \"quarter\", \"is_weekend\", \"dayofyear\", \"is_month_start\", \"is_month_end\".\n\n    Returns\n    -------\n    DataFrame\n        A copy of the DataFrame with the new datetime feature columns added.\n\n    Raises\n    ------\n    ValueError\n        If the datetime_col is missing or if any component in col_types is unsupported.\n\n    Docstring generated with assistance from ChatGPT.\n    \"\"\"\n    supported_types = {\n        \"year\": lambda x: x.dt.year,\n        \"month\": lambda x: x.dt.month,\n        \"day\": lambda x: x.dt.day,\n        \"weekday\": lambda x: x.dt.weekday,\n        \"weekday_name\": lambda x: x.dt.day_name(),\n        \"weekofyear\": lambda x: x.dt.isocalendar().week,\n        \"quarter\": lambda x: x.dt.quarter,\n        \"is_weekend\": lambda x: x.dt.weekday &gt;= 5,\n        \"dayofyear\": lambda x: x.dt.dayofyear,\n        \"is_month_start\": lambda x: x.dt.is_month_start,\n        \"is_month_end\": lambda x: x.dt.is_month_end,\n    }\n\n    if datetime_col not in dataframe.columns:\n        raise ValueError(f\"Column '{datetime_col}' not found in DataFrame.\")\n\n    if isinstance(col_types, str):\n        col_types = [col_types]\n\n    unsupported = [ct for ct in col_types if ct not in supported_types]\n    if unsupported:\n        raise ValueError(\n            f\"Unsupported col_type(s): {unsupported}. Must be one of: {list(supported_types)}\"\n        )\n\n    dataframe = dataframe.copy()\n\n    if not pd.api.types.is_datetime64_any_dtype(dataframe[datetime_col]):\n        # Check for consistent format\n        sample = dataframe[datetime_col].dropna().astype(str)\n        has_dash = sample.str.contains(\"-\").any()\n        has_slash = sample.str.contains(\"/\").any()\n\n        if has_dash and has_slash:\n            raise ValueError(\n                f\"Inconsistent datetime format detected in column '{datetime_col}'. \"\n                \"Mix of '-' and '/' found. Please standardize format before applying datetime expansion.\"\n            )\n\n        try:\n            dataframe[datetime_col] = pd.to_datetime(dataframe[datetime_col])\n        except Exception as e:\n            raise ValueError(f\"Could not convert '{datetime_col}' to datetime: {e}\")\n\n    for col_type in col_types:\n        new_col = f\"{datetime_col}_{col_type}\"\n        dataframe[new_col] = supported_types[col_type](dataframe[datetime_col])\n\n    return dataframe\n</code></pre>"},{"location":"api/#quick-reports","title":"Quick Reports","text":""},{"location":"api/#jcds.eda.reports.display_all_col_head","title":"<code>display_all_col_head(dataframe, head=5)</code>","text":"<p>Display the first few rows of a DataFrame with all columns visible.</p> <p>Temporarily adjusts the pandas display settings to ensure all columns are shown, regardless of the total number, and uses IPython's <code>display()</code> function for clean notebook output.</p>"},{"location":"api/#jcds.eda.reports.display_all_col_head--parameters","title":"Parameters","text":"<p>dataframe : pd.DataFrame     The DataFrame to display. head : int, optional     The number of rows to show from the top of the DataFrame. Defaults to 5.</p>"},{"location":"api/#jcds.eda.reports.display_all_col_head--notes","title":"Notes","text":"<ul> <li>Temporarily sets the pandas display option to show all columns.</li> <li>Uses IPython's <code>display()</code> function for cleaner notebook output.</li> </ul>"},{"location":"api/#jcds.eda.reports.display_all_col_head--returns","title":"Returns","text":"<p>None     This function prints to the notebook interface and does not return a value.</p> <p>Docstring generated with assistance from ChatGPT.</p> Source code in <code>jcds/eda/reports.py</code> <pre><code>def display_all_col_head(dataframe, head=5):\n    \"\"\"\n    Display the first few rows of a DataFrame with all columns visible.\n\n    Temporarily adjusts the pandas display settings to ensure all columns are shown, regardless of the total number,\n    and uses IPython's `display()` function for clean notebook output.\n\n    Parameters\n    ----------\n    dataframe : pd.DataFrame\n        The DataFrame to display.\n    head : int, optional\n        The number of rows to show from the top of the DataFrame. Defaults to 5.\n\n    Notes\n    -----\n    - Temporarily sets the pandas display option to show all columns.\n    - Uses IPython's `display()` function for cleaner notebook output.\n\n    Returns\n    -------\n    None\n        This function prints to the notebook interface and does not return a value.\n\n    Docstring generated with assistance from ChatGPT.\n    \"\"\"\n\n    with pd.option_context(\"display.max_columns\", None):\n        display(dataframe.head(head))\n\n    return\n</code></pre>"},{"location":"api/#jcds.eda.reports.dqr_cat","title":"<code>dqr_cat(dataframe)</code>","text":"<p>Generate a data quality report for categorical features in a given DataFrame.</p> <p>This function calculates and prints the following metrics for each feature in the provided list: - Total count of non-missing values - Total count of missing values - Percentage of missing values - Cardinality (number of unique values) - Mode 1 (most frequent value), its frequency, and percentage - Mode 2 (second most frequent value), its frequency, and percentage - Descriptive statistics for each feature</p>"},{"location":"api/#jcds.eda.reports.dqr_cat--parameters","title":"Parameters","text":"<p>dataframe : pandas.DataFrame     The DataFrame containing the data to be analyzed. list_of_features : list of str     The list of column names (features) for which the data quality report is generated.</p>"},{"location":"api/#jcds.eda.reports.dqr_cat--returns","title":"Returns","text":"<p>None     This function prints the data quality report to the console.</p> <p>Docstring generated with assistance from ChatGPT.</p> Source code in <code>jcds/eda/reports.py</code> <pre><code>def dqr_cat(dataframe):\n    \"\"\"\n    Generate a data quality report for categorical features in a given DataFrame.\n\n    This function calculates and prints the following metrics for each feature in the provided list:\n    - Total count of non-missing values\n    - Total count of missing values\n    - Percentage of missing values\n    - Cardinality (number of unique values)\n    - Mode 1 (most frequent value), its frequency, and percentage\n    - Mode 2 (second most frequent value), its frequency, and percentage\n    - Descriptive statistics for each feature\n\n    Parameters\n    ----------\n    dataframe : pandas.DataFrame\n        The DataFrame containing the data to be analyzed.\n    list_of_features : list of str\n        The list of column names (features) for which the data quality report is generated.\n\n    Returns\n    -------\n    None\n        This function prints the data quality report to the console.\n\n    Docstring generated with assistance from ChatGPT.\n    \"\"\"\n\n    # Initialize variables\n    round_to = 2\n    list_feature_name = []\n    list_count = []\n    list_missing = []\n    list_percent = []\n    list_cardinality = []\n    list_mode1 = []\n    list_mode1_freq = []\n    list_mode1_perc = []\n    list_mode2 = []\n    list_mode2_freq = []\n    list_mode2_perc = []\n\n    # Create list of non-categorical values\n    list_of_features = dataframe.select_dtypes(\n        include=[\"category\", \"object\"]\n    ).columns.tolist()\n\n    # Total rows\n    total_rows = dataframe.shape[0]\n\n    if len(list_of_features) == 0:\n        print(\"This dataset does not have any categorical columns.\")\n        return\n\n    print(\"The categorical features are: \")\n    print(list_of_features)\n\n    for feature in list_of_features:\n\n        total_count = dataframe[feature].count()\n        total_missing = dataframe[feature].isnull().sum()\n        percent_missing = np.round(total_missing / total_rows * 100, round_to)\n        cardinality = len(dataframe[feature].unique())\n\n        # Use value counts to get modes\n        results = dataframe[feature].value_counts()\n        # Calculate mode\n        mode1_name = results.index[0]\n        mode1_count = results.iloc[0]\n        mode1_percent = np.round((mode1_count / total_count) * 100, round_to)\n\n        # Initialize mode 2 variables\n        mode2_name = None\n        mode2_count = 0\n        mode2_percent = 0.0\n\n        # Calculate 2nd mode if it exists\n        if len(results) &gt; 1:\n            mode2_name = results.index[1]\n            mode2_count = results.iloc[1]\n            mode2_percent = np.round((mode2_count / total_count) * 100, round_to)\n\n        # Append results to lists\n        list_feature_name.append(feature)\n        list_count.append(total_count)\n        list_missing.append(total_missing)\n        list_percent.append(percent_missing)\n        list_cardinality.append(cardinality)\n        list_mode1.append(mode1_name)\n        list_mode1_freq.append(mode1_count)\n        list_mode1_perc.append(mode1_percent)\n        list_mode2.append(mode2_name)\n        list_mode2_freq.append(mode2_count)\n        list_mode2_perc.append(mode2_percent)\n\n    # Create dataframes\n    data = {\n        \"Feature\": list_feature_name,\n        \"Count\": list_count,\n        \"Missing\": list_missing,\n        \"% Missing\": list_percent,\n        \"Cardinality\": list_cardinality,\n    }\n\n    data_mode1 = {\n        \"Feature\": list_feature_name,\n        \"Mode 1\": list_mode1,\n        \"Mode 1 Freq.\": list_mode1_freq,\n        \"Mode 1 %\": list_mode1_perc,\n    }\n\n    data_mode2 = {\n        \"Feature\": list_feature_name,\n        \"Mode 2\": list_mode2,\n        \"Mode 2 Freq.\": list_mode2_freq,\n        \"Mode 2 %\": list_mode2_perc,\n    }\n\n    df = pd.DataFrame(data)\n    df1 = pd.DataFrame(data_mode1)\n    df2 = pd.DataFrame(data_mode2)\n\n    # Get descriptive statistics and transpose\n    stats = dataframe[list_of_features].describe(include=\"object\")\n    transposed_stats = stats.T\n\n    # Print results\n    print(\"Data Quality Report for Categorical Features\")\n    print(f\"Total features: {len(list_of_features)} / {total_rows} rows\")\n    print(\"============================================\")\n    print(\"Stats\")\n    print(\"-----\")\n    display(df)\n\n    print(\"\\n\")\n    print(\"Mode 1\")\n    print(\"------\")\n    display(df1)\n\n    print(\"\\n\")\n    print(\"Mode 2\")\n    print(\"------\")\n    display(df2)\n\n    print(\"\\n\")\n    print(\"Descriptive Stats\")\n    print(\"-----------------\")\n    display(transposed_stats)\n\n    return\n</code></pre>"},{"location":"api/#jcds.eda.reports.dqr_cont","title":"<code>dqr_cont(dataframe)</code>","text":"<p>Generate a data quality report for continuous features in a given DataFrame.</p> <p>This function calculates and prints the following metrics for each feature in the provided list: - Total count of non-missing values - Total count of missing values - Percentage of missing values - Cardinality (number of unique values) - Descriptive statistics (mean, standard deviation, min, max)</p>"},{"location":"api/#jcds.eda.reports.dqr_cont--parameters","title":"Parameters","text":"<p>dataframe : pandas.DataFrame     The DataFrame containing the data to be analyzed. list_of_features : list of str     The list of column names (features) for which the data quality report is generated.</p>"},{"location":"api/#jcds.eda.reports.dqr_cont--returns","title":"Returns","text":"<p>None     This function prints the data quality report to the console.</p> <p>Docstring generated with assistance from ChatGPT.</p> Source code in <code>jcds/eda/reports.py</code> <pre><code>def dqr_cont(dataframe):\n    \"\"\"\n    Generate a data quality report for continuous features in a given DataFrame.\n\n    This function calculates and prints the following metrics for each feature in the provided list:\n    - Total count of non-missing values\n    - Total count of missing values\n    - Percentage of missing values\n    - Cardinality (number of unique values)\n    - Descriptive statistics (mean, standard deviation, min, max)\n\n    Parameters\n    ----------\n    dataframe : pandas.DataFrame\n        The DataFrame containing the data to be analyzed.\n    list_of_features : list of str\n        The list of column names (features) for which the data quality report is generated.\n\n    Returns\n    -------\n    None\n        This function prints the data quality report to the console.\n\n    Docstring generated with assistance from ChatGPT.\n    \"\"\"\n\n    # Initialize variables\n    round_to = 2\n    list_feature_name = []\n    list_count = []\n    list_missing = []\n    list_percent = []\n    list_cardinality = []\n\n    # Create list of non-categorical values\n    list_of_features = dataframe.select_dtypes(\n        exclude=[\"category\", \"object\"]\n    ).columns.tolist()\n\n    # Total rows\n    total_rows = dataframe.shape[0]\n\n    if len(list_of_features) == 0:\n        print(\"This dataset does not have any non-categorical features.\")\n        return\n\n    print(\"The non-categorical features are: \")\n    print(list_of_features)\n\n    for feature in list_of_features:\n        # Get stats for each feature\n        total_count = dataframe[feature].count()\n        total_missing = dataframe[feature].isnull().sum()\n        percent_missing = total_missing / total_rows * 100\n        cardinality = len(dataframe[feature].unique())\n\n        # Append result to variables\n        list_feature_name.append(feature)\n        list_count.append(total_count)\n        list_missing.append(total_missing)\n        list_percent.append(np.round(percent_missing, round_to))\n        list_cardinality.append(cardinality)\n\n    # Create dataframe\n    data = {\n        \"Feature\": list_feature_name,\n        \"Count\": list_count,\n        \"Missing\": list_missing,\n        \"% missing\": list_percent,\n        \"Cardinality\": list_cardinality,\n    }\n    df = pd.DataFrame(data)\n\n    # Get descriptive statistics and transpose\n    stats = np.round(dataframe[list_of_features].describe(), round_to)\n    transposed_stats = stats.T\n\n    # Print results\n    print(\"Data Quality for Continous Features\")\n    print(f\"Total Features: {len(list_of_features)} / {total_rows} rows\")\n    display(df)\n\n    print(\"\\n\")\n    print(\"Descriptive Stats\")\n    display(transposed_stats)\n\n    return\n</code></pre>"},{"location":"api/#jcds.eda.reports.long_report","title":"<code>long_report(dataframe)</code>","text":"<p>Generate a detailed summary report of a pandas DataFrame, including shape, missing value statistics, and a breakdown of categorical and continuous features with their unique value counts.</p> <p>This function prints: - Total number of columns and rows - Number and percentage of rows that are entirely missing - Number and percentage of columns with any missing values - Total number of missing values in the dataset - Count of categorical and continuous features - For each categorical and continuous feature: number of unique values</p>"},{"location":"api/#jcds.eda.reports.long_report--notes","title":"Notes","text":"<ul> <li>Categorical features are detected based on 'object' and 'category' dtypes.</li> <li>Continuous features include all other non-categorical dtypes.</li> <li>Missing value percentages are rounded to two decimal places.</li> <li>A placeholder for <code>.info(memory_usage='deep')</code> is printed but not executed.</li> </ul>"},{"location":"api/#jcds.eda.reports.long_report--parameters","title":"Parameters","text":"<p>dataframe : pd.DataFrame     The input DataFrame to analyze.</p>"},{"location":"api/#jcds.eda.reports.long_report--returns","title":"Returns","text":"<p>None     This function prints the detailed summary report to the console.</p> <p>Docstring generated with assistance from ChatGPT.</p> Source code in <code>jcds/eda/reports.py</code> <pre><code>def long_report(dataframe):\n    \"\"\"\n    Generate a detailed summary report of a pandas DataFrame, including shape, missing value statistics,\n    and a breakdown of categorical and continuous features with their unique value counts.\n\n    This function prints:\n    - Total number of columns and rows\n    - Number and percentage of rows that are entirely missing\n    - Number and percentage of columns with any missing values\n    - Total number of missing values in the dataset\n    - Count of categorical and continuous features\n    - For each categorical and continuous feature: number of unique values\n\n    Notes\n    -----\n    - Categorical features are detected based on 'object' and 'category' dtypes.\n    - Continuous features include all other non-categorical dtypes.\n    - Missing value percentages are rounded to two decimal places.\n    - A placeholder for `.info(memory_usage='deep')` is printed but not executed.\n\n    Parameters\n    ----------\n    dataframe : pd.DataFrame\n        The input DataFrame to analyze.\n\n    Returns\n    -------\n    None\n        This function prints the detailed summary report to the console.\n\n    Docstring generated with assistance from ChatGPT.\n    \"\"\"\n\n    ROUND = 2\n    # Get features not labeled as categorical\n    cat_features = dataframe.select_dtypes(\n        include=[\"category\", \"object\"]\n    ).columns.tolist()\n    # Get features labeled as categorical\n    cont_features = dataframe.select_dtypes(\n        exclude=[\"category\", \"object\"]\n    ).columns.tolist()\n    # Get shape, total rows and cols\n    total_rows = dataframe.shape[0]\n    total_cols = dataframe.shape[1]\n    # Count/% rows that are missing values\n    rows_with_all_na = dataframe.isna().all(axis=1).sum()\n    percent_na_rows = np.round(rows_with_all_na / total_rows * 100, ROUND)\n    # Count/% cols that are missing values\n    cols_with_na = dataframe.isna().any(axis=0).sum()\n    percent_na_cols = np.round(cols_with_na / total_cols * 100, ROUND)\n    total_na = dataframe.isna().sum().sum()\n\n    print(\"============================================\")\n    print(\"Quick Report - info(memory_usage='deep')\")\n    print(f\"Total cols: {total_cols}\")\n    print(f\"Rows missing all values: {rows_with_all_na} ({percent_na_rows}%)\")\n    print(f\"Total Rows: {total_rows}\")\n    print(f\"Cols with missing values: {cols_with_na} ({percent_na_cols}%)\")\n    print(f\"Total missing values in dataset: {total_na}\")\n    print(\"============================================\")\n    print(f\"Categorical features: {len(cat_features)}\")\n    for cat in cat_features:\n        num_unique = dataframe[cat].unique()\n        print(f\"- {cat}: {len(num_unique)} unique values\")\n    print(\"============================================\")\n    print(f\"Continuous features: {len(cont_features)}\")\n    for cont in cont_features:\n        num_unique = dataframe[cont].unique()\n        print(f\"- {cont}: {len(num_unique)} unique values\")\n\n    # info = dataframe.info(memory_usage='deep')\n    # display(info)\n    return\n</code></pre>"},{"location":"api/#jcds.eda.reports.quick_report","title":"<code>quick_report(dataframe)</code>","text":"<p>Generate a quick summary report of a pandas DataFrame, including shape, missing value statistics, and memory usage.</p> <p>This function prints: - Total number of columns and rows - Number and percentage of rows that are entirely missing - Number and percentage of columns that have any missing values - Total number of missing values in the dataset - Output of <code>DataFrame.info()</code> with memory usage (<code>deep=True</code>)</p>"},{"location":"api/#jcds.eda.reports.quick_report--notes","title":"Notes","text":"<ul> <li>Categorical and continuous feature identification is performed but not displayed.</li> <li>Missing value calculations are rounded to two decimal places.</li> </ul>"},{"location":"api/#jcds.eda.reports.quick_report--parameters","title":"Parameters","text":"<p>dataframe : pd.DataFrame     The input DataFrame to analyze.</p>"},{"location":"api/#jcds.eda.reports.quick_report--returns","title":"Returns","text":"<p>None     This function prints the summary report to the console.</p> <p>Docstring generated with assistance from ChatGPT.</p> Source code in <code>jcds/eda/reports.py</code> <pre><code>def quick_report(dataframe):\n    \"\"\"\n    Generate a quick summary report of a pandas DataFrame, including shape, missing value statistics, and memory usage.\n\n    This function prints:\n    - Total number of columns and rows\n    - Number and percentage of rows that are entirely missing\n    - Number and percentage of columns that have any missing values\n    - Total number of missing values in the dataset\n    - Output of `DataFrame.info()` with memory usage (`deep=True`)\n\n    Notes\n    -----\n    - Categorical and continuous feature identification is performed but not displayed.\n    - Missing value calculations are rounded to two decimal places.\n\n    Parameters\n    ----------\n    dataframe : pd.DataFrame\n        The input DataFrame to analyze.\n\n    Returns\n    -------\n    None\n        This function prints the summary report to the console.\n\n    Docstring generated with assistance from ChatGPT.\n    \"\"\"\n\n    ROUND = 2\n    # Get features not labeled as categorical\n    cat_features = dataframe.select_dtypes(\n        include=[\"category\", \"object\"]\n    ).columns.tolist()\n    # Get features labeled as categorical\n    cont_features = dataframe.select_dtypes(\n        exclude=[\"category\", \"object\"]\n    ).columns.tolist()\n    # Get shape, total rows and cols\n    total_rows = dataframe.shape[0]\n    total_cols = dataframe.shape[1]\n    # Count/% rows that are missing values\n    rows_with_all_na = dataframe.isna().all(axis=1).sum()\n    percent_na_rows = np.round(rows_with_all_na / total_rows * 100, ROUND)\n    # Count/% cols that are missing values\n    cols_with_na = dataframe.isna().any(axis=0).sum()\n    percent_na_cols = np.round(cols_with_na / total_cols * 100, ROUND)\n    total_na = dataframe.isna().sum().sum()\n\n    print(\"============================================\")\n    print(\"Quick Report - info(memory_usage='deep')\")\n    print(f\"Total cols: {total_cols}\")\n    print(f\"Rows missing all values: {rows_with_all_na} ({percent_na_rows}%)\")\n    print(f\"Total Rows: {total_rows}\")\n    print(f\"Cols with missing values: {cols_with_na} ({percent_na_cols}%)\")\n    print(f\"Total missing values in dataset: {total_na}\")\n    print(\"============================================\")\n</code></pre>"},{"location":"api/#data-inputoutput","title":"Data Input/Output","text":""},{"location":"api/#jcds.dataio.help","title":"<code>help(func_name=None)</code>","text":"<p>Help function for this submodule.</p> <p>Use this function to explore available public functions within the submodule.</p>"},{"location":"api/#jcds.dataio.help--notes","title":"Notes","text":"<ul> <li>Call <code>help()</code> to list all public functions.</li> <li>Call <code>help('function_name')</code> to view documentation for a specific function.</li> </ul> <p>Docstring generated with assistance from ChatGPT.</p> Source code in <code>jcds/dataio/__init__.py</code> <pre><code>def help(func_name=None):\n    \"\"\"\n    Help function for this submodule.\n\n    Use this function to explore available public functions within the submodule.\n\n    Notes\n    -----\n    - Call `help()` to list all public functions.\n    - Call `help('function_name')` to view documentation for a specific function.\n\n    Docstring generated with assistance from ChatGPT.\n    \"\"\"\n\n    functions = {\n        name: globals()[name]\n        for name in __all__\n        if name != \"help\" and callable(globals().get(name))\n    }\n\n    if func_name is None:\n        print(\"Available functions in this module:\")\n        for name in sorted(functions):\n            print(f\"  - {name}\")\n        print('\\nUse help(\"function_name\") to see its documentation.')\n    else:\n        func = functions.get(func_name)\n        if func:\n            print(f\"\\nHelp for '{func_name}':\\n\")\n            print(inspect.getdoc(func) or \"(No docstring provided)\")\n        else:\n            print(f\"Function '{func_name}' not found.\")\n</code></pre>"},{"location":"api/#jcds.dataio.load_parquet","title":"<code>load_parquet(filepath: Union[str, Path], **kwargs) -&gt; pd.DataFrame</code>","text":"<p>Load a Parquet file into a pandas DataFrame.</p>"},{"location":"api/#jcds.dataio.load_parquet--parameters","title":"Parameters","text":"<p>filepath : str or Path     Path to the Parquet file. **kwargs     Additional keyword arguments passed to <code>pd.read_parquet</code>.</p>"},{"location":"api/#jcds.dataio.load_parquet--returns","title":"Returns","text":"<p>pd.DataFrame     The loaded DataFrame.</p>"},{"location":"api/#jcds.dataio.load_parquet--notes","title":"Notes","text":"<p>Requires either <code>pyarrow</code> or <code>fastparquet</code> to be installed.</p> <p>Docstring generated with assistance from ChatGPT.</p> Source code in <code>jcds/dataio/io_utils.py</code> <pre><code>def load_parquet(filepath: Union[str, Path], **kwargs) -&gt; pd.DataFrame:\n    \"\"\"Load a Parquet file into a pandas DataFrame.\n\n    Parameters\n    ----------\n    filepath : str or Path\n        Path to the Parquet file.\n    **kwargs\n        Additional keyword arguments passed to `pd.read_parquet`.\n\n    Returns\n    -------\n    pd.DataFrame\n        The loaded DataFrame.\n\n    Notes\n    -----\n    Requires either `pyarrow` or `fastparquet` to be installed.\n\n    Docstring generated with assistance from ChatGPT.\n    \"\"\"\n    filepath = Path(filepath)\n    return pd.read_parquet(filepath, **kwargs)\n</code></pre>"},{"location":"api/#jcds.dataio.save_parquet","title":"<code>save_parquet(dataframe: pd.DataFrame, filepath: Union[str, Path], **kwargs) -&gt; None</code>","text":"<p>Save a DataFrame to a Parquet file.</p>"},{"location":"api/#jcds.dataio.save_parquet--parameters","title":"Parameters","text":"<p>dataframe : pd.DataFrame     The DataFrame to save. filepath : str or Path     Destination file path. **kwargs     Additional keyword arguments passed to <code>DataFrame.to_parquet</code>.</p>"},{"location":"api/#jcds.dataio.save_parquet--notes","title":"Notes","text":"<p>Automatically creates the parent directory if it doesn't exist.</p> <p>Docstring generated with assistance from ChatGPT.</p> Source code in <code>jcds/dataio/io_utils.py</code> <pre><code>def save_parquet(dataframe: pd.DataFrame, filepath: Union[str, Path], **kwargs) -&gt; None:\n    \"\"\"Save a DataFrame to a Parquet file.\n\n    Parameters\n    ----------\n    dataframe : pd.DataFrame\n        The DataFrame to save.\n    filepath : str or Path\n        Destination file path.\n    **kwargs\n        Additional keyword arguments passed to `DataFrame.to_parquet`.\n\n    Notes\n    -----\n    Automatically creates the parent directory if it doesn't exist.\n\n    Docstring generated with assistance from ChatGPT.\n    \"\"\"\n    filepath = Path(filepath)\n    filepath.parent.mkdir(parents=True, exist_ok=True)\n    dataframe.to_parquet(filepath, index=False, **kwargs)\n</code></pre>"},{"location":"api/#jcds-package-overview","title":"jcds Package Overview","text":"<p>options: members: - help</p>"},{"location":"api/#jcds.help","title":"<code>help(func_name=None)</code>","text":"<p>Global help function for the jcds package.</p> <p>Use this function to explore the functionality provided by the jcds library.</p>"},{"location":"api/#jcds.help--notes","title":"Notes","text":"<ul> <li>Call <code>help()</code> to list all public functions from all submodules.</li> <li>Call <code>help('function_name')</code> to view documentation for a specific function.</li> </ul> <p>Docstring generated with assistance from ChatGPT.</p> Source code in <code>jcds/__init__.py</code> <pre><code>def help(func_name=None):\n    \"\"\"\n    Global help function for the jcds package.\n\n    Use this function to explore the functionality provided by the jcds library.\n\n    Notes\n    -----\n    - Call `help()` to list all public functions from all submodules.\n    - Call `help('function_name')` to view documentation for a specific function.\n\n    Docstring generated with assistance from ChatGPT.\n    \"\"\"\n\n    functions = {}\n\n    # Dynamically import and inspect all top-level jcds submodules\n    for _, mod_name, _ in pkgutil.iter_modules(jcds.__path__):\n        full_name = f\"jcds.{mod_name}\"\n        try:\n            module = importlib.import_module(full_name)\n\n            if hasattr(module, \"__all__\"):\n                for name in module.__all__:\n                    obj = getattr(module, name, None)\n                    if callable(obj) and name != \"help\":\n                        functions[name] = obj\n        except Exception as e:\n            print(f\"[Warning] Could not load module {full_name}: {e}\")\n\n    if func_name is None:\n        if not functions:\n            print(\"No functions found in jcds.\")\n        else:\n            print(\"Available functions in jcds:\")\n            for name in sorted(functions):\n                print(f\"  - {name}\")\n            print('\\nUse jcds.help(\"function_name\") to see its documentation.')\n    else:\n        func = functions.get(func_name)\n        if func:\n            print(f\"\\nHelp for '{func_name}':\\n\")\n            print(inspect.getdoc(func) or \"(No docstring provided)\")\n        else:\n            print(f\"Function '{func_name}' not found.\")\n</code></pre>"}]}